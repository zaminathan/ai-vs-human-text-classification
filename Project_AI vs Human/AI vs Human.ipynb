{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAM4osdP5tja",
        "outputId": "8498331e-903d-4e51-837e-42c2451f4b73"
      },
      "outputs": [],
      "source": [
        "\n",
        "from flask import Flask, request, jsonify\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1ikzWGylaQj0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import pickle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5rzFTnyaVIP",
        "outputId": "b1da82ed-30bc-4e85-981c-8a9af782ba76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4b4jYf_UaXH8"
      },
      "outputs": [],
      "source": [
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "app = Flask(__name__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "bob90DODaZ2y"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = [word for word in text.split() if word not in stop_words]\n",
        "    return ' '.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2qV6r7pza1NO"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('large_ai_human_generated_text_dataset_fixed (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Mn3If37Ka3WW"
      },
      "outputs": [],
      "source": [
        "df['cleaned_paragraph'] = df['Paragraph'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0sf27Vg1a6hJ"
      },
      "outputs": [],
      "source": [
        "x = df['cleaned_paragraph']\n",
        "y = df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "YMsTUAkEa9iE"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "p35t1uxvbAVQ"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
        "x_test_tfidf = vectorizer.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeh6Nf_abHo8",
        "outputId": "60e87119-7433-432c-c322-5b4c8919faf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        90\n",
            "           1       1.00      1.00      1.00       110\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(x_train_tfidf, y_train)\n",
        "y_pred = model.predict(x_test_tfidf)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save model\n",
        "with open('model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save vectorizer\n",
        "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('model.pkl', 'rb') as model_file:\n",
        "    model = pickle.load(model_file)\n",
        "with open('vectorizer.pkl', 'rb') as vectorizer_file:\n",
        "    vectorizer = pickle.load(vectorizer_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5eRpKLuaGZ5",
        "outputId": "f3f1b9f6-3015-4740-b932-ccd672f63c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI-generated\n"
          ]
        }
      ],
      "source": [
        "def predict_paragraph(text):\n",
        "    processed_text = preprocess_text(text)\n",
        "    vectorized_text = vectorizer.transform([processed_text])\n",
        "    prediction = model.predict(vectorized_text)\n",
        "    return \"AI-generated\" if prediction == 1 else \"Human-generated\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "test_text = \"Artificial intelligence has greatly improved automation capabilities.\"\n",
        "print(predict_paragraph(test_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je62zo3TaGVQ",
        "outputId": "a0009b81-a83e-4561-f122-11d427fe3b5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI-generated\n"
          ]
        }
      ],
      "source": [
        "test_text = \"GPT-3 has been instrumental in natural language generation tasks.\"\n",
        "print(predict_paragraph(test_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcPY-Hyrfjb7",
        "outputId": "813d450a-10c9-42cc-a5ee-83f78f3c1673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human-generated\n"
          ]
        }
      ],
      "source": [
        "test_text_1=(\"The sun was setting over the mountains, casting a golden glow over the valley below Birds were chirping as the cool evening breeze gently swayed the trees\")\n",
        "print(predict_paragraph(test_text_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYXQ8lYmaGTa",
        "outputId": "791026f9-aed1-481d-8695-351017679d38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:5000\n",
            "Press CTRL+C to quit\n",
            " * Restarting with watchdog (windowsapi)\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "1",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    text = request.json['text']\n",
        "    prediction = predict_paragraph(text)\n",
        "    return jsonify({'prediction': prediction})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0oq9hOGaGO_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_input_and_predict():\n",
        "  text = input(\"Enter the text: \")\n",
        "  prediction = predict_paragraph(text)\n",
        "  print(f\"Prediction: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wggvSn2vaGMn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Human-generated\n"
          ]
        }
      ],
      "source": [
        "get_input_and_predict()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
